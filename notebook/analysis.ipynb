{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Backtesting: We look at incorporating a _Tailored Designed_ algos, as an ENTRY signal.**\n",
    "**Features**\n",
    "- Resamples 1 minute data from a local/CSV to 15 minutes. (currenlty using h5 files saved on Google-Drive)\n",
    "- Uses Numba, TA-Lib (and for the cherry on top, joblib), to further speed up the computation.\n",
    "- VectorBT Indicator Factory to comprise all the smaller indicators into one super indicator (Numba, TA-Lib and Joblib for speed) as we deal with various ranges of parameters.\n",
    "- Dynamic take profit - Generating exit signals using Moving Average cloud cross and MACD Histogram.\n",
    "- Trailing stop loss.\n",
    "- Cross validates, by filtering entries on odd dates and compare the best optimized results with entries on the even dates.\n",
    "- Plotting with Seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE_STOCHASTIC = True  # if True TD entries take STOCHASTIC values into account whether STOCHASTIC is based on RSI or HLC values else only TD Sequential is used for entries.\n",
    "ENABLE_TRAILING_SL = False  # if True portfolio is simulated using Trailing Stop Loss, else it is done using basic Stop Loss\n",
    "\n",
    "ENABLE_TP_VALUE = False  # if True uses Take profit values else uses Dynamic TP (IF Dynamic TP IS NOT FALSE)\n",
    "DYNAMIC_TP_SETTING = 'both'  #'ma_cloud', 'macd', 'both' or False\n",
    "\"\"\"\n",
    "if 'ma_cloud', exit signals are generated using cloud strategy\n",
    "if 'macd' exit signals are generated when histogram crosses below 0\n",
    "if 'both' exit signals are generated using ma_cloud + macd\n",
    "if False exit only based on stop loss or trailing stop loss\n",
    "\"\"\"\n",
    "# ----------------------------------------------------------------\n",
    "# Note: If both TP values are utilized then signals are calculated in combination\n",
    "# Take profit values + cloud or take profit values + both etc.\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "STOP_ORDER_SETTING = 'percent'  # absoulte or percent value\n",
    "\"\"\"\n",
    "if 'absolute' use absolute terms\n",
    "if 'percent' use percentage where 0.01 == 1%\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import vectorbtpro as vbt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn  # conda install -y -c anaconda seaborn\n",
    "import talib\n",
    "\n",
    "from datetime import datetime\n",
    "from joblib import Memory  # conda install -y joblib\n",
    "from numba import njit\n",
    "\n",
    "import gdown  # conda install -y -c conda-forge gdown\n",
    "import os\n",
    "# esnure widgets are installed to see progress bar:\n",
    "# conda install -y -c conda-forge ipywidgets=7.7.2\n",
    "\n",
    "memory = Memory(location='joblib_cache_dir', verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorbt setting for dark theme for plotting.\n",
    "vbt.settings.set_theme(\"dark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT_DATA_TYPE = 'spx'  # select from 'spx', 'wti'\n",
    "SELECT_DATA_YEAR = 2018  # select from 2014-2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add to git ignore\n",
    "SELECT_DOWNLOAD_DATA = 'all'\n",
    "# Set to 'all' if all h5 files should be download from drive (warning: large file > 300MB)\n",
    "# Set to 'select' if only the SELECT_DATA_YEAR file should be downloaded\n",
    "MY_FILENAME_CSV = str(SELECT_DATA_TYPE) + '_' + str(SELECT_DATA_YEAR) + '.csv'\n",
    "MY_FILENAME_H5 = str(SELECT_DATA_TYPE) + '_' + str(\n",
    "    SELECT_DATA_YEAR) + '_data.h5'\n",
    "\n",
    "# Data folder: https://drive.google.com/drive/u/0/folders/1iyHMZoMDNrqNenjEECNPpGlb_k5AKbhn\n",
    "DRIVE_LINKS = {}\n",
    "DRIVE_LINKS[2014] = '1Na9UJiDabeKdVSuvk6B_5VASYpqrtmHm'\n",
    "DRIVE_LINKS[2015] = '1ppCGhAqFnn-08jGnafdnYE6lrsKUscBX'\n",
    "DRIVE_LINKS[2016] = '1sYXweNNBRyx1_EEdELEpw1sTBJo5-jdB'\n",
    "DRIVE_LINKS[2017] = '1Cf08sqBuYFaE1zqJGC3QdU2wHY0ukZGS'\n",
    "DRIVE_LINKS[2018] = '1R1ZNr7P2d0U-Re_Xg0zp7EVwZgpk4zHm'\n",
    "DRIVE_LINKS[2019] = '1zqpRGZFmAlhjT-VyJtRcoXY5MTW3jGsU'\n",
    "DRIVE_LINKS[2020] = '1JVEEXRd8J1EOv2DZmm-fiB7FpJTdIsm6'\n",
    "DRIVE_LINKS[2021] = '1THZnlU65a_v4Q72zN-yFh3UNspbegCax'\n",
    "\n",
    "# Check if filename hdf exists in local directory\n",
    "if os.path.isfile('data/' + MY_FILENAME_H5) == True:\n",
    "    print(f\"The file '{MY_FILENAME_H5}' exists in the directory.\")\n",
    "\n",
    "else:\n",
    "    print(f\"The file '{MY_FILENAME_H5}' does not exist in the directory\")\n",
    "\n",
    "    if SELECT_DOWNLOAD_DATA == 'select':\n",
    "        print(\"Downloading one year dataset\")\n",
    "        output = 'data/' + MY_FILENAME_H5\n",
    "        id = DRIVE_LINKS[SELECT_DATA_YEAR]\n",
    "        gdown.download(id=id, output=output, quiet=False)\n",
    "\n",
    "    elif SELECT_DOWNLOAD_DATA == 'all':\n",
    "        print(\"Downloading entire dataset\")\n",
    "        id = '1Bdasv20K1jlf6pKJe7TR80kFlakBHagy'\n",
    "        gdown.download_folder(id=id, quiet=True, use_cookies=False)\n",
    "\n",
    "    else:\n",
    "        print(\"Checking for CSV file\")\n",
    "\n",
    "        if os.path.isfile(MY_FILENAME_CSV) == False:\n",
    "            print(\n",
    "                f\"The file '{MY_FILENAME_CSV}' does not exist in the current directory. Please download manually\"\n",
    "            )\n",
    "        else:\n",
    "            # Read from local csv\n",
    "            csv = pd.read_csv(MY_FILENAME_CSV, index_col=0, parse_dates=True)\n",
    "            data = vbt.Data.from_data({'close': csv})\n",
    "            h1_data = data.to_hdf('data/' + MY_FILENAME_H5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resmaple to 15min\n",
    "h1_data = vbt.HDFData.fetch('data/' + MY_FILENAME_H5)\n",
    "m15_data = h1_data.resample('15T')\n",
    "m15_data = m15_data.get().dropna()  # Drop NaN values for every column\n",
    "\n",
    "m15_data = m15_data.assign(even=pd.Series(\n",
    "    m15_data.index.day %\n",
    "    2 == 0).values)  # Append a bool column where values for even days are True\n",
    "m15_data = m15_data.assign(odd=pd.Series(\n",
    "    m15_data.index.day %\n",
    "    2 != 0).values)  # Append a bool column where values for odd days are True\n",
    "\n",
    "high = m15_data.get('high')\n",
    "low = m15_data.get('low')\n",
    "close = m15_data.get('close')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example \"Tailored Designed\" inidcator, detect 3 candles up in a row\n",
    "@memory.cache  # For faster computation and memory caching to restore from memory\n",
    "@njit(nogil=True)  # Using Numba for compiling\n",
    "def tds_nb(source, max_count=3, signal_count=3):\n",
    "    dna = np.full(source.shape, 0)\n",
    "    upa = np.full(source.shape, 0)\n",
    "    buy_sig = np.full(source.shape, False)\n",
    "    sell_sig = np.full(source.shape, False)\n",
    "\n",
    "    for i in range(4, source.shape[0]):\n",
    "\n",
    "        if source[i] < source[i - 1]:\n",
    "            upa[i] = upa[i - 1] + 1  # increment by 1\n",
    "            if upa[i] > max_count:\n",
    "                upa[i] = 1  # wrap count back to 1, on max count\n",
    "            if upa[i] == signal_count:\n",
    "                buy_sig[i] = True\n",
    "\n",
    "        if source[i] > source[i - 1]:\n",
    "            dna[i] = dna[i - 1] + 1  # increment by 1\n",
    "            if dna[i] > max_count:\n",
    "                dna[i] = 1  # wrap count back to 1, on max count\n",
    "            if dna[i] == signal_count:\n",
    "                sell_sig[i] = True\n",
    "\n",
    "    return buy_sig, sell_sig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def stochastic_rsi(source, rsi_period, slowd_period, rsi_oversold_level):\n",
    "    fastk_period = rsi_period\n",
    "    slowk_period = slowd_period\n",
    "\n",
    "    RSI = talib.RSI(close, rsi_period)\n",
    "    slowk, slowd = talib.STOCH(RSI, RSI, RSI, fastk_period, slowk_period,\n",
    "                               slowd_period)\n",
    "\n",
    "    buy_strsi = np.where(slowk <= rsi_oversold_level, True, False)\n",
    "\n",
    "    return buy_strsi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create more inidcators, these can be used for smarter/dynamic exits for optimal take-proit\n",
    "@memory.cache\n",
    "def ma_indicator(source, fastma_period, slowma_period):\n",
    "    fast_ma = talib.SMA(close, timeperiod=fastma_period)\n",
    "    slow_ma = talib.SMA(close, timeperiod=slowma_period)\n",
    "\n",
    "    return fast_ma, slow_ma\n",
    "\n",
    "\n",
    "@memory.cache\n",
    "def macd_indicator(source, fastmacd_period, slowmacd_period,\n",
    "                   signalmacd_period):\n",
    "    macd, macdsignal, macdhist = talib.MACD(close,\n",
    "                                            fastperiod=fastmacd_period,\n",
    "                                            slowperiod=slowmacd_period,\n",
    "                                            signalperiod=signalmacd_period)\n",
    "\n",
    "    return macdhist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicator function for entries and exits computation, uses TD Sequential, Stochastic RSI, MA and MACD\n",
    "\n",
    "\n",
    "def super_indicator(source, max_count, signal_count, rsi_period, slowd_period,\n",
    "                    rsi_oversold_level, fastma_period, slowma_period,\n",
    "                    fastmacd_period, slowmacd_period, signalmacd_period):\n",
    "\n",
    "    buy_tds, _ = tds_nb(source, max_count, signal_count)\n",
    "    buy_strsi = stochastic_rsi(source, rsi_period, slowd_period,\n",
    "                               rsi_oversold_level)\n",
    "    fast_ma, slow_ma = ma_indicator(source, fastma_period, slowma_period)\n",
    "    macdh = macd_indicator(source, fastmacd_period, slowmacd_period,\n",
    "                           signalmacd_period)\n",
    "\n",
    "    return buy_tds, buy_strsi, fast_ma, slow_ma, macdh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IF template, so we can generate many parameters later\n",
    "super_indicator_vbt = vbt.IF(\n",
    "    class_name='super_indicator_vbt',\n",
    "    short_name='super_indicator_vbt',\n",
    "    prepend_name=True,\n",
    "    input_names=['close'],\n",
    "    param_names=[\n",
    "        'max_count', 'signal_count', 'rsi_period', 'slowd_period',\n",
    "        'rsi_oversold_level', 'fastma_period', 'slowma_period',\n",
    "        'fastmacd_period', 'slowmacd_period', 'signalmacd_period'\n",
    "    ],\n",
    "    output_names=['buy_tds', 'buy_strsi', 'fast_ma', 'slow_ma',\n",
    "                  'macdh']).with_apply_func(super_indicator,\n",
    "                                            takes_1d=True,\n",
    "                                            max_count=3,\n",
    "                                            signal_count=3,\n",
    "                                            rsi_period=14,\n",
    "                                            slowd_period=3,\n",
    "                                            rsi_oversold_level=30,\n",
    "                                            fastma_period=30,\n",
    "                                            slowma_period=100,\n",
    "                                            fastmacd_period=12,\n",
    "                                            slowmacd_period=26,\n",
    "                                            signalmacd_period=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all math/inidcators needed\n",
    "super_indicator = super_indicator_vbt.run(\n",
    "    close,\n",
    "    max_count=3,\n",
    "    signal_count=3,\n",
    "    rsi_period=40,\n",
    "    slowd_period=4,\n",
    "    rsi_oversold_level=30,\n",
    "    fastma_period=10,\n",
    "    slowma_period=21,\n",
    "    fastmacd_period=np.arange(8, 13),\n",
    "    slowmacd_period=np.arange(13, 28),\n",
    "    signalmacd_period=np.arange(7, 30),\n",
    "    param_product=True,\n",
    "    execute_kwargs=dict(show_progress=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entries:  Find best parameters for entries on ODD days\n",
    "# Filter out stochastic entries based on setting input\n",
    "if ENABLE_STOCHASTIC:\n",
    "    entries = super_indicator.buy_tds_equal(\n",
    "        1) & super_indicator.buy_strsi_equal(1)\n",
    "\n",
    "elif not ENABLE_STOCHASTIC:\n",
    "    entries = super_indicator.buy_tds_equal(1)\n",
    "\n",
    "for x in range(entries.shape[1]):\n",
    "    entries.iloc[:, x] = np.where(\n",
    "        np.logical_and(entries.iloc[:, x] == True, m15_data['odd'] == True),\n",
    "        True, False)  # Filter out entries for odd days only\n",
    "\n",
    "# Exits using indicators, instead of hard take-profit levels\n",
    "exits_ma = (super_indicator.close_crossed_below(super_indicator.fast_ma)\n",
    "            & super_indicator.fast_ma_above(super_indicator.slow_ma)) | (\n",
    "                super_indicator.close_crossed_below(super_indicator.slow_ma)\n",
    "                & super_indicator.slow_ma_above(super_indicator.fast_ma))\n",
    "\n",
    "exits_macd = super_indicator.macdh_crossed_below(0)\n",
    "\n",
    "# Filter out dynamic take profit conditions based on setting input\n",
    "if DYNAMIC_TP_SETTING == 'both':\n",
    "    exits = exits_ma | exits_macd\n",
    "\n",
    "elif DYNAMIC_TP_SETTING == 'ma_cloud':\n",
    "    exits = exits_ma\n",
    "\n",
    "elif DYNAMIC_TP_SETTING == 'macd':\n",
    "    exits = exits_macd\n",
    "\n",
    "else:\n",
    "    exits = np.full(\n",
    "        entries.shape, False\n",
    "    )  # Create a numpy array of False values with the shape of entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Trailing Stop Loss, to reduce drawdown\n",
    "# Filter out stop order values based on setting input\n",
    "if ENABLE_TP_VALUE:\n",
    "    tp = [20, 40, 60]\n",
    "\n",
    "elif not ENABLE_TP_VALUE:\n",
    "    tp = np.nan\n",
    "\n",
    "if ENABLE_TRAILING_SL:\n",
    "\n",
    "    if STOP_ORDER_SETTING == 'percent':\n",
    "        # tsl = [0.001, 0.0005]\n",
    "        # tsl = [0.001, 0.0005, 0.0001]\n",
    "        tsl = [0.000333]\n",
    "\n",
    "    else:\n",
    "        # tsl = [1, 2, 3]\n",
    "        tsl = [1, 2]\n",
    "\n",
    "    sl = np.nan\n",
    "\n",
    "elif not ENABLE_TRAILING_SL:\n",
    "    tsl = np.nan\n",
    "\n",
    "    if STOP_ORDER_SETTING == 'percent':\n",
    "        # sl = [0.01, 0.02, 0.03]\n",
    "        sl = [0.000333]\n",
    "    else:\n",
    "        # sl = [1, 2, 3]\n",
    "        sl = [1, 2]\n",
    "\n",
    "pf = vbt.Portfolio.from_signals(close=close,\n",
    "                                entries=entries,\n",
    "                                exits=exits,\n",
    "                                size=2700 * 50,\n",
    "                                size_type='value',\n",
    "                                init_cash='auto',\n",
    "                                sl_stop=vbt.Param(sl),\n",
    "                                tsl_stop=vbt.Param(tsl),\n",
    "                                tp_stop=vbt.Param(tp),\n",
    "                                delta_format=STOP_ORDER_SETTING,\n",
    "                                fixed_fees=20,\n",
    "                                freq='15m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to file\n",
    "\n",
    "# Get current timestamp and suffix to filename\n",
    "now = datetime.now()\n",
    "timestamp_str = now.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "file_path = f'results {timestamp_str}'\n",
    "\n",
    "param_result_matrix = pf.stats(\n",
    "    ['total_return', 'max_dd', 'win_rate', 'sortino_ratio'], agg_func=None)\n",
    "param_result_matrix = param_result_matrix.sort_values('Sortino Ratio',\n",
    "                                                      ascending=False)\n",
    "\n",
    "# only profitable\n",
    "# param_result_matrix = param_result_matrix[\n",
    "#     param_result_matrix['Total Return [%]'] > 1]\n",
    "\n",
    "param_result_matrix.to_csv(f'{file_path}.csv')\n",
    "param_result_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scatter-matrix for\n",
    "\n",
    "re_read_csv = pd.read_csv(f'{file_path}.csv')\n",
    "seaborn.pairplot(re_read_csv, x_vars=['Sortino Ratio'], kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print best result values\n",
    "best_result = param_result_matrix.sort_values('Sortino Ratio',\n",
    "                                              ascending=False).iloc[0]\n",
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best parameters from ODD days, and test on EVEN days (blind test!)\n",
    "# If EVEN days are also profitable, we might have a good strategy\n",
    "\n",
    "best_sl = best_result.name[0]\n",
    "best_tsl = best_result.name[1]\n",
    "best_tp = best_result.name[2]\n",
    "best_td_max = best_result.name[3]\n",
    "best_td_signal = best_result.name[4]\n",
    "best_rsi_period = best_result.name[5]\n",
    "best_sto_rsi_slowd = best_result.name[6]\n",
    "best_oversold_level = best_result.name[7]\n",
    "best_fastma_period = best_result.name[8]\n",
    "best_slowma_period = best_result.name[9]\n",
    "best_fastmacd_period = best_result.name[10]\n",
    "best_slowmacd_period = best_result.name[11]\n",
    "best_signalmacd_period = best_result.name[12]\n",
    "\n",
    "super_indicator = super_indicator_vbt.run(\n",
    "    close,\n",
    "    max_count=best_td_max,\n",
    "    signal_count=best_td_signal,\n",
    "    rsi_period=best_rsi_period,\n",
    "    slowd_period=best_sto_rsi_slowd,\n",
    "    rsi_oversold_level=best_oversold_level,\n",
    "    fastma_period=best_fastma_period,\n",
    "    slowma_period=best_slowma_period,\n",
    "    fastmacd_period=best_fastmacd_period,\n",
    "    slowmacd_period=best_slowmacd_period,\n",
    "    signalmacd_period=best_signalmacd_period)\n",
    "\n",
    "best_entries = super_indicator.buy_tds_equal(\n",
    "    1) & super_indicator.buy_strsi_equal(1)\n",
    "best_entries = np.where(\n",
    "    np.logical_and(best_entries == True, m15_data['even'] == True), True,\n",
    "    False)  # Filter out entries for even days only\n",
    "\n",
    "best_exits_ma = (\n",
    "    super_indicator.close_crossed_below(super_indicator.fast_ma)\n",
    "    & super_indicator.fast_ma_above(super_indicator.slow_ma)) | (\n",
    "        super_indicator.close_crossed_below(super_indicator.slow_ma)\n",
    "        & super_indicator.slow_ma_above(super_indicator.fast_ma))\n",
    "best_exits_macd = super_indicator.macdh_crossed_below(0)\n",
    "\n",
    "# Dynamic Take Profit setting\n",
    "if DYNAMIC_TP_SETTING == 'both':\n",
    "    best_exits = best_exits_ma | best_exits_macd\n",
    "\n",
    "elif DYNAMIC_TP_SETTING == 'ma_cloud':\n",
    "    best_exits = best_exits_ma\n",
    "\n",
    "elif DYNAMIC_TP_SETTING == 'macd':\n",
    "    best_exits = best_exits_macd\n",
    "\n",
    "else:\n",
    "    best_exits = np.full(\n",
    "        best_entries.shape, False\n",
    "    )  # Create a numpy array of False values with the shape of entries\n",
    "\n",
    "pf1 = vbt.Portfolio.from_signals(close=close,\n",
    "                                 entries=best_entries,\n",
    "                                 exits=best_exits,\n",
    "                                 size=2700 * 50,\n",
    "                                 size_type='value',\n",
    "                                 init_cash='auto',\n",
    "                                 sl_stop=best_sl,\n",
    "                                 tsl_stop=best_tsl,\n",
    "                                 tp_stop=best_tp,\n",
    "                                 delta_format=STOP_ORDER_SETTING,\n",
    "                                 fixed_fees=20,\n",
    "                                 freq='15m')\n",
    "\n",
    "print(pf1.stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fast plot\n",
    "vbt.settings.plotting[\"use_resampler\"] = True  # fast plots, but resmapling :(\n",
    "pf1.plot().show()\n",
    "\n",
    "# detailed plot\n",
    "# vbt.settings.plotting[\"use_resampler\"] = False\n",
    "# fig = pf1.plot()  # 45s\n",
    "# fig.update_layout(showlegend=False,\n",
    "#                   hovermode=False)  # faster plots without re-smapling :)\n",
    "# fig.write_html(fpath + '.html', config={'responsive': True})  # 18s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare best result for entries taken on odd days with entries taken on even days\n",
    "# Odd days - Optimize performance\n",
    "print(f'Entries filtered on Odd Days \\n{best_result}\\n')\n",
    "\n",
    "# Even days - Based on the best combination of parameters from odd days simulation\n",
    "even_days_result = pf1.stats(\n",
    "    ['total_return', 'max_dd', 'win_rate', 'sortino_ratio'])\n",
    "print(f'Entries filtered on Even Days \\n{even_days_result}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c30f2af5f468e7f5b45bcc30fca5f4886c90d54777aed916ed5f6294dfb24bf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
